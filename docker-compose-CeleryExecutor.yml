version: '2.1'
services:
    rabbitmq:
        container_name: rabbitmq
        image: rabbitmq:3-management
        ports:
            - "15672:15672"
            - "5672:5672"
        environment:
            - RABBITMQ_DEFAULT_USER=airflow
            - RABBITMQ_DEFAULT_PASS=airflow
            - RABBITMQ_DEFAULT_VHOST=airflow
        healthcheck:
          test: ["CMD", "rabbitmqctl", "status"]
          interval: 5s
          timeout: 5s
          retries: 5

    postgres:
        container_name: postgres
        image: postgres:9.6
        ports:
          - 5432:5432
        environment:
          - POSTGRES_USER=airflow
          - POSTGRES_PASSWORD=airflow
          - POSTGRES_DB=airflow
        healthcheck:
          test: ["CMD-SHELL", "pg_isready -U airflow"]
          interval: 10s
          timeout: 5s
          retries: 5
        # Uncomment these lines to persist data on the local filesystem.
        #     - PGDATA=/var/lib/postgresql/data/pgdata
        # volumes:
        #     - ./pgdata:/var/lib/postgresql/data/pgdata

    webserver:
        container_name: airflow
        image: bjmrq/airflow-reportpipeline
        restart: always
        depends_on:
          - postgres
          - rabbitmq
        environment:
          - LOAD_EX=n
          - EXECUTOR=Celery
          - POSTGRES_USER=airflow
          - POSTGRES_PASSWORD=airflow
          - POSTGRES_DB=airflow
          - RABBITMQ_DEFAULT_USER=admin
          - RABBITMQ_HOST=rabbitmq
          - RABBITMQ_DEFAULT_PASS=rabbitmq
          - FERNET_KEY=8HI5iPy4iQWPoABO6C7ECKXMCxKlDdCGG45dnHlMzdA=
        volumes:
          - ./dags:/usr/local/airflow/dags
          - ./plugins:/usr/local/airflow/plugins
          - ./tests:/usr/local/airflow/tests
          - ./data:/usr/local/airflow/data
        ports:
          - "8080:8080"
        command: webserver
        healthcheck:
          test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
          interval: 60s
          timeout: 60s
          retries: 3

            # - POSTGRES_USER=airflow
            # - POSTGRES_PASSWORD=airflow
            # - POSTGRES_DB=airflow
            # - REDIS_PASSWORD=redispass

    flower:
        container_name: flower
        image: bjmrq/airflow-reportpipeline
        restart: always
        depends_on:
            - rabbitmq
        environment:
            - EXECUTOR=Celery
            - RABBITMQ_DEFAULT_USER=admin
            - RABBITMQ_HOST=rabbitmq
            - RABBITMQ_DEFAULT_PASS=rabbitmq
            - FERNET_KEY=8HI5iPy4iQWPoABO6C7ECKXMCxKlDdCGG45dnHlMzdA=
        ports:
            - "5555:5555"
        command: flower

    scheduler:
        container_name: scheduler
        image: bjmrq/airflow-reportpipeline
        restart: always
        depends_on:
            - webserver
        environment:
          - LOAD_EX=n
          - EXECUTOR=Celery
          - POSTGRES_USER=airflow
          - POSTGRES_PASSWORD=airflow
          - POSTGRES_DB=airflow
          - RABBITMQ_DEFAULT_USER=admin
          - RABBITMQ_HOST=rabbitmq
          - RABBITMQ_DEFAULT_PASS=rabbitmq
          - FERNET_KEY=8HI5iPy4iQWPoABO6C7ECKXMCxKlDdCGG45dnHlMzdA=
        volumes:
          - ./dags:/usr/local/airflow/dags
          - ./plugins:/usr/local/airflow/plugins
          - ./tests:/usr/local/airflow/tests
          - ./data:/usr/local/airflow/data
        command: scheduler

    worker:
        container_name: worker
        image: bjmrq/airflow-reportpipeline
        restart: always
        depends_on:
            - scheduler
        environment:
          - LOAD_EX=n
          - EXECUTOR=Celery
          - POSTGRES_USER=airflow
          - POSTGRES_PASSWORD=airflow
          - POSTGRES_DB=airflow
          - RABBITMQ_DEFAULT_USER=admin
          - RABBITMQ_HOST=rabbitmq
          - RABBITMQ_DEFAULT_PASS=rabbitmq
          - FERNET_KEY=8HI5iPy4iQWPoABO6C7ECKXMCxKlDdCGG45dnHlMzdA=
        volumes:
          - ./dags:/usr/local/airflow/dags
          - ./plugins:/usr/local/airflow/plugins
          - ./tests:/usr/local/airflow/tests
          - ./data:/usr/local/airflow/data
        command: worker
